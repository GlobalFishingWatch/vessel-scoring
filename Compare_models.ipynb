{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare models\n",
    "\n",
    "This compares several different models trained in turn on the *longliner*,\n",
    "*trawler* and *purse seiner* data sets.\n",
    "\n",
    "**NOTE: this was somewhat unstable. Running multiple times yielded significantly different results, \n",
    "  depending the data split.  I set seeds everywhere and now the output is stable. However, this tells \n",
    "  me that we want more data!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import vessel_scoring.data\n",
    "from vessel_scoring.evaluate_model import evaluate_model, train_model\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'windows'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e7b8b1c2331f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m untrained_models = [\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0;34m'Logistic'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLogisticModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m43200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'Logistic (MW)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLogisticModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1800\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3600\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10800\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m21600\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m43200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m86400\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'Logistic (MW/cross)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLogisticModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1800\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3600\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10800\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m21600\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m43200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m86400\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'windows'"
     ]
    }
   ],
   "source": [
    "from vessel_scoring.legacy_heuristic_model import LegacyHeuristicModel\n",
    "from vessel_scoring.random_forest_model import RandomForestModel\n",
    "from vessel_scoring.logistic_model import LogisticModel\n",
    "\n",
    "untrained_models = [\n",
    "    ('Logistic', LogisticModel(windows=[43200], order=6)),\n",
    "    ('Logistic (MW)', LogisticModel(windows=[1800, 3600, 10800, 21600, 43200, 86400], order=6)),\n",
    "    ('Logistic (MW/cross)', LogisticModel(windows=[1800, 3600, 10800, 21600, 43200, 86400], order=6, cross=2)),\n",
    "    ('Random Forest', RandomForestModel(windows=[43200])),\n",
    "    ('Random Forest (MW)', RandomForestModel(windows=[1800, 3600, 10800, 21600, 43200, 86400])),\n",
    "    ('Legacy', LegacyHeuristicModel(window=3600)),\n",
    "    (\"Legacy (3 Hour)\", LegacyHeuristicModel(window=10800)),\n",
    "    (\"Legacy (12 Hour)\", LegacyHeuristicModel(window=43200)),\n",
    "    (\"Legacy (24 Hour)\", LegacyHeuristicModel(window=86400)),  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for vessel_class in [\"longliner\", \"trawl\", \"ps\"]:\n",
    "    display(HTML(\"<h1>Comparison for {0}</h1>\".format(vessel_class)))\n",
    "    x, xtrain, xcross, xtest = data.load_dataset_by_vessel(\n",
    "            'datasets/kristina_{0}.measures.npz'.format(vessel_class))\n",
    "    trained_models = [(name, train_model(mdl, xtrain)) for (name, mdl) in untrained_models]\n",
    "    for name, mdl in trained_models:\n",
    "        evaluate_model(mdl, xtest, name=name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
